{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f138c40",
   "metadata": {},
   "source": [
    "## 1.4. DQN\n",
    "接下来我们来研究Q-Learning。我们首先来介绍两种值函数：状态值函数$v_{\\pi}(s)$和状态行动值函数$q_{\\pi}(s,a)$。在业界也将这两个函数称为Critic，即评判者，可以用于评价策略$\\pi$的好坏，并据此对策略进行改进，也就是著名的Q-Learning，以及其对应的深度学习版本DQN。\n",
    "### 1.4.1. 状态值函数\n",
    "状态值函数$v_{\\pi}(s)$表求在状态$s$可以获得的累积奖励的期望值：\n",
    "$$\n",
    "v_{\\pi}=E(G_{t}|S_{t}=s)\n",
    "$$\n",
    "#### 1.4.1.1. Monte Carlo法\n",
    "#### 1.4.1.2. Temporal Difference法\n",
    "#### 1.4.1.3. MV vs TD\n",
    "### 1.4.2. 状态行动值函数\n",
    "### 1.4.3. Q-Learning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
