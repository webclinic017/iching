---
title: 深度学习理论001-001：预备知识
created: '2021-06-26T06:43:14.799Z'
modified: '2021-06-26T13:11:52.798Z'
---

# 深度学习理论001-001：预备知识
## 1.1. 高斯积分
### 1.1.1. 单变量高斯积分
给定如下函数：
$$
e^{-\frac{x^{2}}{2}} 
\tag{1.1}
$$
我们可以使用如下函数，绘制函数图像：
```python
# doc/dlt/chp01/sec01/e01_01_01.py
import numpy as np
import matplotlib.pyplot as plt

class E010101(object):
    def __init__(self):
        self.name = ''

    def startup(self):
        print('第1章 预备知识 第1节 高斯积分 例1 类高斯函数图像')
        x = np.arange(-10.0, 10.0, 0.01)
        y = np.exp(-x*x/2)
        fig, ax = plt.subplots()
        plt.plot(x, y)
        ax.set(xlabel='x', ylabel='y',
            title='raw gaussian')
        ax.grid()
        #fig.savefig('./work/p010101.png')
        plt.show()

def main(args={}):
    exp = E010101()
    exp.startup()

if '__main__' == __name__:
    main()
```
其函数图像为：
![Raw Gaussian](D:/zjkj/iching/doc/dlt/images/p01_01_01.png)
我们定义该函数的积分形式为：
$$
I_{1} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx
\tag{1.2}
$$
直接求这个积分是比较困难的，我们可以求其平方的积分，如下所示：
$$
I_{1}^{2} = \bigg( \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \bigg)^{2} \quad \bigstar ^{1} \\
= \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \\
= \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \int _{-\infty}^{\infty} e^{-\frac{y^{2}}{2}} dy \\
= \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} e^{-\frac{x^{2}+y^{2}}{2}} dxdy
\tag{1.3}
$$
接下来，我们将坐标由直角坐标系$(x, y)$转换为极坐标$(r, \theta)$，该变换的公式为：
$$
x = r \cos \theta \\
y = r \sin \theta
\tag{1.4}
$$
我们在直角坐标系下二重积分的区域$dxdy$在极坐标下可以表示为：
![polar cord](D:/zjkj/iching/doc/dlt/images/p01_01_02.png)
我们知道园的面积为$A=\pi r^{2}$，而园的角度为$2 \pi$，所以每弧度的面积为：
$$
apa = \frac{\pi r^{2}}{2 \pi} = \frac{1}{2} r^{2} 
\tag{1.5}
$$
假设扇形的夹角为$\theta$，其面积公式为：
$$
A = \frac{1}{2} r^{2} \theta
\tag{1.6}
$$
所以上图中积分区域为两个扇形面积之差：
$$
dxdy = d \sigma = \frac{1}{2} (r + \Delta r)^{2} \Delta \theta - \frac{1}{2} r^{2} \Delta \theta \\
= \frac{1}{2}r^{2} \Delta \theta + r \Delta r \Delta \theta + \Delta r ^{2} \Delta \theta - \frac{1}{2} r^{2} \Delta \theta \\
= r \Delta r \Delta \theta + \Delta r ^{2} \Delta \theta \\
= r \Delta r \Delta \theta + 0 (\Delta r  \Delta \theta) \\
\approx r dr d\theta
\tag{1.7}
$$
我们将上述结果代入式$(1.3)$得：
$$
I_{1}^{2} = \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} e^{-\frac{x^{2}+y^{2}}{2}} dxdy \\
= \int _{0}^{\infty} \int _{0}^{2 \pi} e ^{- \frac{r^{2}(\cos \theta)^2 + r^{2}(\sin \theta)^{2}}{2}} rdrd\theta \\
= \int _{0}^{\infty} \int _{0}^{2 \pi} r e ^{- \frac{r^{2}}{2}} drd\theta \\
= \int _{0}^{\infty} r e ^{- \frac{r^{2}}{2}} dr \int _{0}^{2 \pi} d\theta \\
= 2 \pi \int _{0}^{\infty} r e ^{- \frac{r^{2}}{2}} dr \\
= 2 \pi \bigg[ - e^{-\frac{r}{2}} \bigg] _{0}^{\infty} = 2 \pi
\tag{1.8}
$$
由此我们可以得出：
$$
I_{1} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx = \sqrt{2 \pi}
\tag{1.9}
$$
我们知道对于连续随机变量$X$的概率密度函数$pdf$在$(-\infty, \infty)$上积分为1：
$$
\int _{-\infty}^{\infty} p(x)dx=1
\tag{1.10}
$$
我们可以将式$(1.1)$所表示的函数转变为概率密度函数：
$$
p(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{x^{2}}{2}}
\tag{1.11}
$$
式$(1.11)$就是我们经常用到的标准正态分布，其均值$\mu = 0.0$，方差$\sigma ^{2} = 1.0$。
下面我们来讨论方差$\sigma ^{2} \neq 1.0$的情况：
$$
I_{K}=\int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2 \sigma ^{2}}} dx
\tag{1.13}
$$
我们令$u=\frac{x}{\sigma}$，并代入式$(1.13)$得：
$$
I_{K} = \int _{-\infty}^{\infty} e^{-\frac{(u\sigma)^{2}}{2 \sigma ^{2}}} d(u\sigma) \\
=\sigma \int _{-\infty}^{\infty} e^{-\frac{u^{2}}{2}} du \\
= \sigma \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \\
= \sqrt{2 \pi} \sigma = \sqrt{2 \pi \sigma ^{2}}
\tag{1.14}
$$
此时我们可以定义概率密度函数为：
$$
p(x)=\frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{x^{2}}{2 \sigma ^{2}}} 
\tag{1.15}
$$
我们定义均值为$\mu$，则更一般的概率密度函数为：
$$
p(x)=\frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma ^{2}}} 
\tag{1.16}
$$
按照上面的概率密度函数，我们可以证明式$(1.16)$中的$\mu$就是均值：
$$
E[x] = \int _{-\infty}^{\infty} xp(x)dx \\
= \int _{-\infty}^{\infty} x \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma ^{2}}} dx
\tag{1.17}
$$
我们令$u=x-\mu$，则$x=u+\mu$，则式$(1.17)$变为：
$$
E[x] = \int _{-\infty}^{\infty} x \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma ^{2}}} dx \\
= \int _{-\infty}^{\infty} (u+\mu) \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{u^{2}}{2 \sigma ^{2}}} d(u+\mu) \\
= \int _{-\infty}^{\infty} u \cdot \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{u^{2}}{2 \sigma ^{2}}} du + \mu \int _{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{u^{2}}{2 \sigma ^{2}}} du \quad \bigstar^{1} \\
= 0 + \mu = \mu
\tag{1.18}
$$
式$(1.18)$中注1：第1项为奇函数对原点对称区间积分，其值为0。
因此我们由式$(1.18)$可以看出，$\mu$就是均值。

## Wick定理
我们在高斯积分中引入源项$J$，如下所示：
$$
X_{\sigma ^{2}, J} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2 \sigma ^{2}} + Jx} dx
\tag{1.19}
$$
如果我们设$J=0$则有$X_{\sigma ^{2}, 0}=I_{\sigma ^{2}}$，就变为标准的高斯分布了。$Z_{\sigma ^{2}, J}$又叫有源配分函数（Partition Function with Source）。
我们先来看式$(1.19)$的指数项：
$$
-\frac{x^{2}}{2 \sigma ^{2}} + Jx = -\frac{(x-J\sigma ^{2})^{2} + 2xJ\sigma ^{2} - J^{2}\sigma ^{4}}{2\sigma ^{2}} + \frac{2Jx\sigma ^{2}}{2\sigma ^{2}} \\
= -\frac{(x - J\sigma ^{2})^{2}}{2 \sigma ^{2}} + \frac{J^{2}\sigma ^{2}}{2}
\tag{1.20}
$$
将式$(1.20)$代入式$(1.19)$可得：
$$
X_{\sigma ^{2}, J} = e^{\frac{J^{2}\sigma ^{2}}{2}} \int _{-\infty}^{\infty} e^{-\frac{(x - J\sigma ^{2})^{2}}{2\sigma ^{2}}} dx = e^{\frac{J^{2}\sigma ^{2}}{2}} \sqrt{2 \pi \sigma ^{2}}
\tag{1.21}
$$
我们计算$I_{\sigma ^{2}, m}$：
$$
I_{\sigma ^{2}, m} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2\sigma ^{2}}} x^{2m} dx \\
= \Bigg( \frac{d^{2m}}{dJ^{2m}} \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2\sigma ^{2}} + Jx} dx \Bigg) \Bigg \vert _{J=0} \\
= \Bigg( \frac{d^{2m}}{dJ^{2m}} X_{\sigma ^{2}, J} \Bigg) \Bigg \vert _{J=0} \\
= \sqrt{2 \pi \sigma ^{2}} \Bigg( \frac{d^{2m}}{dJ^{2m}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \quad \bigstar ^{1}
\tag{1.22}
$$
注1：我们将式$(1.21)$代入公式中；
我们先来研究几个特殊情况，然后再来看一般情况。我们首先来研究$m=1$即$2m=2$的情况：
$$
E[x^{2}] = \int _{-\infty}^{\infty} x^{2} \frac{1}{\sqrt{2\pi \sigma ^{2}}} e^{-\frac{x^{2}}{2 \sigma ^{2}}} dx \\
=\frac{1}{\sqrt{2\pi \sigma ^{2}}} \int _{-\infty}^{\infty} x^{2} e^{-\frac{x^{2}}{2 \sigma ^{2}}} dx \quad \bigstar ^{1} \\
= \frac{1}{\sqrt{2\pi \sigma ^{2}}} \sqrt{2 \pi \sigma ^{2}} \Bigg( \frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \\
= \Bigg( \frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0}
\tag{1.23}
$$
注：
* 1：将式$(1.22)$代入；

我们对式$(1.23)$求一阶导数：
$$
\frac{d}{dJ} e^{\frac{J^{2}\sigma ^{2}}{2}} = e^{\frac{J^{2}\sigma ^{2}}{2}} J\sigma ^{2}
\tag{1.24}
$$
我再对式$(1.24)$求导就等于对式$(1.23)$求二阶导数：
$$
\frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} = \frac{d}{dJ} e^{\frac{J^{2}\sigma ^{2}}{2}} J\sigma ^{2} \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} J\sigma ^{2} J\sigma ^{2} + e^{\frac{J^{2}\sigma ^{2}}{2}} \sigma ^{2} \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{2}\sigma ^{4} + \sigma ^{2})
\tag{1.25}
$$
将式$(1.25)$代入式$(1.23)$可得：
$$
E[x^{2}] = \Bigg( \frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \\
= \Bigg( e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{2}\sigma ^{4} + \sigma ^{2}) \Bigg) \Bigg \vert _{J=0} \\
=\sigma ^{2}
$$



要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
