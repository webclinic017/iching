---
tags: [Import-61ab]
title: 深度学习理论001-001：预备知识
created: '2021-06-27T03:25:05.688Z'
modified: '2021-06-27T15:03:20.843Z'
---

---
title: 深度学习理论001-001：预备知识
created: '2021-06-26T06:43:14.799Z'
modified: '2021-06-26T13:11:52.798Z'
---

# 深度学习理论001-001：预备知识
## 1.1. 高斯积分
### 1.1.1. 单变量高斯积分
给定如下函数：
$$
e^{-\frac{x^{2}}{2}} 
\tag{1.1}
$$
我们可以使用如下函数，绘制函数图像：
```python
# doc/dlt/chp01/sec01/e01_01_01.py
import numpy as np
import matplotlib.pyplot as plt

class E010101(object):
    def __init__(self):
        self.name = ''

    def startup(self):
        print('第1章 预备知识 第1节 高斯积分 例1 类高斯函数图像')
        x = np.arange(-10.0, 10.0, 0.01)
        y = np.exp(-x*x/2)
        fig, ax = plt.subplots()
        plt.plot(x, y)
        ax.set(xlabel='x', ylabel='y',
            title='raw gaussian')
        ax.grid()
        #fig.savefig('./work/p010101.png')
        plt.show()

def main(args={}):
    exp = E010101()
    exp.startup()

if '__main__' == __name__:
    main()
```
其函数图像为：
![Raw Gaussian](D:/zjkj/iching/doc/dlt/images/p01_01_01.png)
我们定义该函数的积分形式为：
$$
I_{1} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx
\tag{1.2}
$$
直接求这个积分是比较困难的，我们可以求其平方的积分，如下所示：
$$
I_{1}^{2} = \bigg( \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \bigg)^{2} \quad \bigstar ^{1} \\
= \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \\
= \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \int _{-\infty}^{\infty} e^{-\frac{y^{2}}{2}} dy \\
= \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} e^{-\frac{x^{2}+y^{2}}{2}} dxdy
\tag{1.3}
$$
接下来，我们将坐标由直角坐标系$(x, y)$转换为极坐标$(r, \theta)$，该变换的公式为：
$$
x = r \cos \theta \\
y = r \sin \theta
\tag{1.4}
$$
我们在直角坐标系下二重积分的区域$dxdy$在极坐标下可以表示为：
![polar cord](D:/zjkj/iching/doc/dlt/images/p01_01_02.png)
我们知道园的面积为$A=\pi r^{2}$，而园的角度为$2 \pi$，所以每弧度的面积为：
$$
apa = \frac{\pi r^{2}}{2 \pi} = \frac{1}{2} r^{2} 
\tag{1.5}
$$
假设扇形的夹角为$\theta$，其面积公式为：
$$
A = \frac{1}{2} r^{2} \theta
\tag{1.6}
$$
所以上图中积分区域为两个扇形面积之差：
$$
dxdy = d \sigma = \frac{1}{2} (r + \Delta r)^{2} \Delta \theta - \frac{1}{2} r^{2} \Delta \theta \\
= \frac{1}{2}r^{2} \Delta \theta + r \Delta r \Delta \theta + \Delta r ^{2} \Delta \theta - \frac{1}{2} r^{2} \Delta \theta \\
= r \Delta r \Delta \theta + \Delta r ^{2} \Delta \theta \\
= r \Delta r \Delta \theta + 0 (\Delta r  \Delta \theta) \\
\approx r dr d\theta
\tag{1.7}
$$
我们将上述结果代入式$(1.3)$得：
$$
I_{1}^{2} = \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} e^{-\frac{x^{2}+y^{2}}{2}} dxdy \\
= \int _{0}^{\infty} \int _{0}^{2 \pi} e ^{- \frac{r^{2}(\cos \theta)^2 + r^{2}(\sin \theta)^{2}}{2}} rdrd\theta \\
= \int _{0}^{\infty} \int _{0}^{2 \pi} r e ^{- \frac{r^{2}}{2}} drd\theta \\
= \int _{0}^{\infty} r e ^{- \frac{r^{2}}{2}} dr \int _{0}^{2 \pi} d\theta \\
= 2 \pi \int _{0}^{\infty} r e ^{- \frac{r^{2}}{2}} dr \\
= 2 \pi \bigg[ - e^{-\frac{r}{2}} \bigg] _{0}^{\infty} = 2 \pi
\tag{1.8}
$$
由此我们可以得出：
$$
I_{1} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx = \sqrt{2 \pi}
\tag{1.9}
$$
我们知道对于连续随机变量$X$的概率密度函数$pdf$在$(-\infty, \infty)$上积分为1：
$$
\int _{-\infty}^{\infty} p(x)dx=1
\tag{1.10}
$$
我们可以将式$(1.1)$所表示的函数转变为概率密度函数：
$$
p(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{x^{2}}{2}}
\tag{1.11}
$$
式$(1.11)$就是我们经常用到的标准正态分布，其均值$\mu = 0.0$，方差$\sigma ^{2} = 1.0$。
下面我们来讨论方差$\sigma ^{2} \neq 1.0$的情况：
$$
I_{K}=\int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2 \sigma ^{2}}} dx
\tag{1.13}
$$
我们令$u=\frac{x}{\sigma}$，并代入式$(1.13)$得：
$$
I_{K} = \int _{-\infty}^{\infty} e^{-\frac{(u\sigma)^{2}}{2 \sigma ^{2}}} d(u\sigma) \\
=\sigma \int _{-\infty}^{\infty} e^{-\frac{u^{2}}{2}} du \\
= \sigma \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2}} dx \\
= \sqrt{2 \pi} \sigma = \sqrt{2 \pi \sigma ^{2}}
\tag{1.14}
$$
此时我们可以定义概率密度函数为：
$$
p(x)=\frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{x^{2}}{2 \sigma ^{2}}} 
\tag{1.15}
$$
我们定义均值为$\mu$，则更一般的概率密度函数为：
$$
p(x)=\frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma ^{2}}} 
\tag{1.16}
$$
按照上面的概率密度函数，我们可以证明式$(1.16)$中的$\mu$就是均值：
$$
E[x] = \int _{-\infty}^{\infty} xp(x)dx \\
= \int _{-\infty}^{\infty} x \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma ^{2}}} dx
\tag{1.17}
$$
我们令$u=x-\mu$，则$x=u+\mu$，则式$(1.17)$变为：
$$
E[x] = \int _{-\infty}^{\infty} x \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma ^{2}}} dx \\
= \int _{-\infty}^{\infty} (u+\mu) \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{u^{2}}{2 \sigma ^{2}}} d(u+\mu) \\
= \int _{-\infty}^{\infty} u \cdot \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{u^{2}}{2 \sigma ^{2}}} du + \mu \int _{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma ^{2}}} e^{-\frac{u^{2}}{2 \sigma ^{2}}} du \quad \bigstar^{1} \\
= 0 + \mu = \mu
\tag{1.18}
$$
式$(1.18)$中注1：第1项为奇函数对原点对称区间积分，其值为0。
因此我们由式$(1.18)$可以看出，$\mu$就是均值。

## Wick定理
我们在高斯积分中引入源项$J$，如下所示：
$$
X_{\sigma ^{2}, J} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2 \sigma ^{2}} + Jx} dx
\tag{1.19}
$$
如果我们设$J=0$则有$X_{\sigma ^{2}, 0}=I_{\sigma ^{2}}$，就变为标准的高斯分布了。$Z_{\sigma ^{2}, J}$又叫有源配分函数（Partition Function with Source）。
我们先来看式$(1.19)$的指数项：
$$
-\frac{x^{2}}{2 \sigma ^{2}} + Jx = -\frac{(x-J\sigma ^{2})^{2} + 2xJ\sigma ^{2} - J^{2}\sigma ^{4}}{2\sigma ^{2}} + \frac{2Jx\sigma ^{2}}{2\sigma ^{2}} \\
= -\frac{(x - J\sigma ^{2})^{2}}{2 \sigma ^{2}} + \frac{J^{2}\sigma ^{2}}{2}
\tag{1.20}
$$
将式$(1.20)$代入式$(1.19)$可得：
$$
X_{\sigma ^{2}, J} = e^{\frac{J^{2}\sigma ^{2}}{2}} \int _{-\infty}^{\infty} e^{-\frac{(x - J\sigma ^{2})^{2}}{2\sigma ^{2}}} dx = e^{\frac{J^{2}\sigma ^{2}}{2}} \sqrt{2 \pi \sigma ^{2}}
\tag{1.21}
$$
我们计算$I_{\sigma ^{2}, m}$：
$$
I_{\sigma ^{2}, m} = \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2\sigma ^{2}}} x^{2m} dx \\
= \Bigg( \frac{d^{2m}}{dJ^{2m}} \int _{-\infty}^{\infty} e^{-\frac{x^{2}}{2\sigma ^{2}} + Jx} dx \Bigg) \Bigg \vert _{J=0} \\
= \Bigg( \frac{d^{2m}}{dJ^{2m}} X_{\sigma ^{2}, J} \Bigg) \Bigg \vert _{J=0} \\
= \sqrt{2 \pi \sigma ^{2}} \Bigg( \frac{d^{2m}}{dJ^{2m}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \quad \bigstar ^{1}
\tag{1.22}
$$
注1：我们将式$(1.21)$代入公式中；
我们先来研究几个特殊情况，然后再来看一般情况。我们首先来研究$m=1$即$2m=2$的情况：
$$
E[x^{2}] = \int _{-\infty}^{\infty} x^{2} \frac{1}{\sqrt{2\pi \sigma ^{2}}} e^{-\frac{x^{2}}{2 \sigma ^{2}}} dx \\
=\frac{1}{\sqrt{2\pi \sigma ^{2}}} \int _{-\infty}^{\infty} x^{2} e^{-\frac{x^{2}}{2 \sigma ^{2}}} dx \quad \bigstar ^{1} \\
= \frac{1}{\sqrt{2\pi \sigma ^{2}}} \sqrt{2 \pi \sigma ^{2}} \Bigg( \frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \\
= \Bigg( \frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0}
\tag{1.23}
$$
注：
* 1：将式$(1.22)$代入；

我们对式$(1.23)$求一阶导数：
$$
\frac{d}{dJ} e^{\frac{J^{2}\sigma ^{2}}{2}} = e^{\frac{J^{2}\sigma ^{2}}{2}} J\sigma ^{2}
\tag{1.24}
$$
我再对式$(1.24)$求导就等于对式$(1.23)$求二阶导数：
$$
\frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} = \frac{d}{dJ} e^{\frac{J^{2}\sigma ^{2}}{2}} J\sigma ^{2} \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} J\sigma ^{2} J\sigma ^{2} + e^{\frac{J^{2}\sigma ^{2}}{2}} \sigma ^{2} \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{2}\sigma ^{4} + \sigma ^{2})
\tag{1.25}
$$
将式$(1.25)$代入式$(1.23)$可得：
$$
E[x^{2}] = \Bigg( \frac{d^{2}}{dJ^{2}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \\
= \Bigg( e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{2}\sigma ^{4} + \sigma ^{2}) \Bigg) \Bigg \vert _{J=0} \\
=\sigma ^{2}
\tag{1.26}
$$

我们对式$(1.25)$继续求3阶导数：
$$
\frac{d^{3}}{dJ^{3}} e^{\frac{J^{2}\sigma ^{2}}{2}} \\
= \frac{d}{dJ} \bigg( e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{2}\sigma ^{4} + \sigma ^{2}) \bigg) \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} J \sigma ^{2} (J^{2}\sigma ^{4} + \sigma ^{2}) + e^{\frac{J^{2}\sigma ^{2}}{2}} (2J\sigma ^{4}) \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} ( J^{3}\sigma ^{6} + J\sigma ^{4} + 2J\sigma ^{4} ) \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{3}\sigma ^{6} + 3J\sigma ^{4})
\tag{1.27}
$$
接下来我们求4阶导数：
$$
\frac{d^{4}}{dJ^{4}} e^{\frac{J^{2}\sigma ^{2}}{2}} \\
= \frac{d}{dJ} \bigg( e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{3}\sigma ^{6} + 3J\sigma ^{4}) \bigg) \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} J\sigma ^{2} (J^{3}\sigma ^{6} + 3J\sigma ^{4}) + e^{\frac{J^{2}\sigma ^{2}}{2}} (3J^{2}\sigma ^{6} + 3\sigma ^{4}) \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} (J^{4}\sigma ^{8} + 3J^{2}\sigma ^{6} + 3J^{2}\sigma ^{6} + 3\sigma ^{4}) \\
= e^{\frac{J^{2}\sigma ^{2}}{2}} ( J^{4}\sigma ^{8} + 6J^{2}\sigma ^{6} + 3\sigma ^{4})
\tag{1.28}
$$

当$m=2$则$2m=4$时，根据式$(1.23)$定义有：
$$
E[x^{4}] = \Bigg( \frac{d^{4}}{dJ^{4}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \\
= \bigg( e^{\frac{J^{2}\sigma ^{2}}{2}} ( J^{4}\sigma ^{8} + 6J^{2}\sigma ^{6} + 3\sigma ^{4}) \bigg)\Bigg \vert _{J=0} \\
= 3\sigma ^{4}
\tag{1.29}
$$
对更一般的公式为：
$$
E[x^{2m}] = \Bigg( \frac{d^{2m}}{dJ^{2m}} e^{\frac{J^{2}\sigma ^{2}}{2}} \Bigg) \Bigg \vert _{J=0} \\
= \Bigg( \frac{d^{2m}}{dJ^{2m}} ( \sum_{k=0}^{\infty} \frac{1}{k!} (\frac{\sigma ^{2}}{2})^{k}J^{2k} ) \Bigg) \Bigg \vert _{J=0} \\
= \frac{d^{2m}}{dJ^{2m}} ( \frac{1}{m!} (\frac{\sigma ^{2}}{2})^{m} J^{2m}) \\
= \sigma ^{2m} \frac{(2m)!}{m!2^{m}} \\
= \sigma ^{2m} (2m-1)!!
\tag{1.30}
$$
这个就是著名的Wick定理。

## 多元高斯分布
在上一节中，我们讨论了一元高斯分布下的高斯积分，接下来我们讨论多元高斯分布。
这时我们的随机变量是一个向量$\boldsymbol{x}$：
$$
\boldsymbol{x}=\begin{bmatrix}
x_1 \\
x_2 \\
... \\
x_n 
\end{bmatrix}, \boldsymbol{x} \in R^{n}
\tag{1.31}
$$
以上向量$\boldsymbol{x}$的每一维都是一个随机变量，定义$\mu _{i} = E[x_{i}]$，则可以得到均值向量$\boldsymbol{\mu}$：
$$
\boldsymbol{\mu}=\begin{bmatrix}
\mu _{1} \\
\mu _{2} \\
... \\
\mu _{n}
\end{bmatrix}
\tag{1.32}
$$
两个随机变量$x_{i}$和$x_{j}$的协方差定义为：
$$
conv(x_{i}, x_{j}) = E[(x_{i} - \mu _{i})(x_{j} - \mu _{j})] = \frac{1}{m} \sum_{k=1}^{m} (x_{i,k}-\mu _{i})(x_{j,k} - \mu _{j})
\tag{1.33}
$$
我们可以定协方差矩阵：
$$
\Sigma = \begin{bmatrix}
conv(x_{1}, x_{1}) & conv(x_{1}, x_{2}) & ... & conv(x_{1}, x_{n}) \\
conv(x_{2}, x_{1}) & conv(x_{2}, x_{2}) & ... & conv(x_{2}, x_{n}) \\
...... \\
conv(x_{n}, x_{1}) & conv(x_{n}, x_{2}) & ... & conv(x_{n}, x_{n}) 
\end{bmatrix}
\tag{1.34}
$$
我们可以用向量形式进行简化：
$$
\Sigma = \frac{1}{n}(\boldsymbol{x} - \boldsymbol{\mu})(\boldsymbol{x} - \boldsymbol{\mu})^{T}
\tag{1.35}
$$
注意：这里的$\Sigma$是一个以$\boldsymbol{x}$为自变量的函数。有了上述定义之后，我们就可以得到多元高斯分布的概率密度函数：
$$
p(\boldsymbol{x}; \boldsymbol{\mu}, \Sigma) = \frac{1}{(2\pi)^{\frac{n}{2}} |\Sigma|^{\frac{1}{2}} } e^{-\frac{1}{2}(\boldsymbol{x} - \boldsymbol{\mu})^{T}\Sigma ^{-1}(\boldsymbol{x} - \boldsymbol{\mu})} 
\tag{1.36}
$$
以上是矩阵和向量形式表示的多元高斯分布公式，其实我们也可以将上式写成元素查乘的形式，我们首先来看指数部分，为了简化起见，我们均假设均值为0且维度$n=3$：
$$
\boldsymbol{x}^{T}\Sigma ^{-1} \boldsymbol{x} = \begin{bmatrix}
x_{1} & x_{2} & x_{3}
\end{bmatrix} 
\begin{bmatrix}
\Sigma _{1,1}^{-1} & \Sigma _{1,2}^{-1} & \Sigma _{1,3}^{-1} \\
\Sigma _{2,1}^{-1} & \Sigma _{2,2}^{-1} & \Sigma _{2,3}^{-1} \\
\Sigma _{3,1}^{-1} & \Sigma _{3,2}^{-1} & \Sigma _{3,3}^{-1}
\end{bmatrix}
\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix} \\
=\begin{bmatrix}
x_{1}\Sigma _{1,1}^{-1} + x_{2}\Sigma _{2,1}^{-1} + x_{3}\Sigma _{3,1}^{-1} & x_{1}\Sigma _{1,2}^{-1} + x_{2}\Sigma _{2,2}^{-1} + x_{3}\Sigma _{3,2}^{-1} & x_{1}\Sigma _{1,3}^{-1} + x_{2}\Sigma _{2,3}^{-1} + x_{3}\Sigma _{3,3}^{-1}
\end{bmatrix}
\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix} \\
= x_{1}\Sigma _{1,1}^{-1}x_{1} + x_{2}\Sigma _{2,1}^{-1}x_{1} + x_{3}\Sigma _{3,1}^{-1}x_{1} + x_{1}\Sigma _{1,2}^{-1}x_{2} + x_{2}\Sigma _{2,2}^{-1}x_{2} + x_{3}\Sigma _{3,2}^{-1}x_{2} + x_{1}\Sigma _{1,3}^{-1}x_{3} + x_{2}\Sigma _{2,3}^{-1}x_{3} + x_{3}\Sigma _{3,3}^{-1}x_{3} \\
= \sum_{i=1}^{n}\sum_{j=1}^{n} x_{i} \Sigma _{i,j}^{-1} x_{j} \\
= \sum_{i,j=1}^{n} x_{i} \Sigma _{i,j}^{-1} x_{j}
\tag{1.37}
$$
而且对于$\Sigma$有：
$$
\Sigma \Sigma ^{-1} = I_{n}
\tag{1.38}
$$
将上式写为坐标形式为：
$$
\sum_{k=1}^{n} \Sigma _{i,k}^{-1} \Sigma _{k,j} = \delta _{i,j}
\tag{1.39}
$$
其中$\delta _{i,j}$定义为：
$$
\delta _{i,j} = \begin{cases}
1, \quad i=j \\
0, \quad i \neq j
\end{cases}
\tag{1.40}
$$
我们定义多元高斯分布的归一化因子：
$$
I_{\Sigma} = \int _{-\infty}^{\infty} dx_{1} \int _{-\infty}^{\infty} dx_{2} ... \int _{-\infty}^{\infty} e^{-\frac{1}{2}\sum_{i,j=1}^{n} x_{i} \Sigma _{i,j}^{-1} x_{j} } dx_{n}
\tag{1.41}
$$
我们知道$\Sigma$是对称矩阵，根据线性代数的谱定理，其存$n$个实特征值和正交特征向量，即：
$$
D = O^{T} \Sigma O
\tag{1.42}
$$
其中矩阵$P$的列为$\Sigma$的特征向量，并且互相垂直且为单位向量，$D$为对角阵，对角线元素为$\Sigma$的特征值，通常按由大到小顺序排列，并与$P$的列对应，并且有$O^{T}=O^{-1}$。
我们知道$D$为对象阵，元素为从大到小排列的特征值，因此有如下公式：
$$
(O\Sigma O^{T})_{i,j}=\lambda _{i} \delta _{i,j}
\tag{1.43}
$$
同理对于$\Sigma ^{-1}$有如下公式：
$$
(O\Sigma ^{-1} O^{T})_{i,j}=\frac{1}{\lambda _{i}} \delta _{i,j}
\tag{1.44}
$$
式中的$\delta _{i,j}$定义见式$(1.40)$，当$i=j$时为1，其余时为0。
下面我们先推出矩阵表示形式，然后再推导出坐标表示形式。因为$OO^{T}=I$，而乘上单位阵值不变，对于指数部分：
$$
\boldsymbol{x}^{T} \Sigma ^{-1} \boldsymbol{x} = \boldsymbol{x}^{T} (O^{T}O) \Sigma ^{-1} (O^{T}O) \boldsymbol{x} \\
= \boldsymbol{x}^{T} O^{T} (O\Sigma ^{-1} O^{T}) O\boldsymbol{x} \\
= (O\boldsymbol{x})^{T} D O\boldsymbol{x}
\tag{1.45}
$$
其中$D$为对角阵：
$$
D = \begin{bmatrix}
\frac{1}{\lambda _{1}} & 0 & ... & 0 \\
0 & \frac{1}{\lambda _{2}} & ... & 0 \\
... \\
0 & 0 & ... & \frac{1}{\lambda _{n}}
\end{bmatrix}
\tag{1.46}
$$
我们令$\boldsymbol{u}=O\boldsymbol{x}$，将式$(1.45)$写为坐标形式：
$$
\boldsymbol{u}^{T} D \boldsymbol{u} = \begin{bmatrix}
u_{1} & u_{2} & ... & u_{n}
\end{bmatrix}
\begin{bmatrix}
\frac{1}{\lambda _{1}} & 0 & ... & 0 \\
0 & \frac{1}{\lambda _{2}} & ... & 0 \\
... \\
0 & 0 & ... & \frac{1}{\lambda _{n}}
\end{bmatrix}
\begin{bmatrix}
u_{1} \\
u_{2} \\
... \\
u_{n}
\end{bmatrix} \\
= \begin{bmatrix}
u_{1} \frac{1}{\lambda _{1}} & u_{2} \frac{1}{\lambda _{2}} & ... & u_{n}\frac{1}{\lambda _{n}}
\end{bmatrix}
\begin{bmatrix}
u_{1} \\
u_{2} \\
... \\
u_{n}
\end{bmatrix} \\
= u_{1} \frac{1}{\lambda _{1}} u_{1} + u_{2} \frac{1}{\lambda _{2}} u_{2} + ... + u_{n}\frac{1}{\lambda _{n}} u_{n} \\
= \frac{1}{\lambda _{1}} u_{1}^{2} + \frac{1}{\lambda _{2}} u_{2}^{2} + ... + \frac{1}{\lambda _{n}} u_{n}^{2}
= \sum_{i=1}^{n} \frac{1}{\lambda _{i}} u_{i}^{2}
\tag{1.47}
$$
将式$(1.47)$代入式$(1.45)$可得：
$$
\boldsymbol{x}^{T} \Sigma ^{-1} \boldsymbol{x} = \sum_{i=1}^{n} \frac{1}{\lambda _{i}} (O\boldsymbol{x})_{i}^{2}
\tag{1.48}
$$
令$\boldsymbol{u}=O\boldsymbol{x}$，因为$O$为正交矩阵，所以有：
$$
d^{n} x = d^{n} u
\tag{1.49}
$$
代入$(式1.45)$，则归一化因子为：
$$
I_{\Sigma} = \int _{-\infty}^{\infty} dx_{1} \int _{-\infty}^{\infty} dx_{2} ... \int _{-\infty}^{\infty} e^{-\frac{1}{2}\sum_{i,j=1}^{n} x_{i} \Sigma _{i,j}^{-1} x_{j} } dx_{n} \\
= \int _{-\infty}^{\infty} du_{1} \int _{-\infty}^{\infty} du_{2} ... \int _{-\infty}^{\infty} e^{-\frac{1}{2}\sum_{i=1}^{n} \frac{u_{i}^{2}}{\lambda _{i}} } du_{n} \\
= \prod_{i=1}^{n} \bigg( \int _{-\infty}^{infty} e^{-\frac{u_{i}^{2}}{2\lambda _{i}}} du \bigg) \\
= \prod_{i=1}^{n} \sqrt{2\pi \lambda _{i}} \\
=  \sqrt{ \prod_{i=1}^{n} 2\pi \lambda _{i}} \\
= \sqrt{|2\pi \Sigma|}  \\
=\sqrt{(2\pi)^{n}|\Sigma|} \quad \bigstar^{1}
\tag{1.50}
$$
注：
1. 这是更加通用表示方式；

所以多元高斯分布的概率密度函数可以定义为：
$$
p(\boldsymbol{x}) = \frac{1}{\sqrt{(2\pi)^{n}|\Sigma|}} e^{-\frac{1}{2}\sum_{i,j=1}^{n} x_{i} \Sigma _{i,j}^{-1} x_{j} }
\tag{1.51}
$$
更一般的形式为：
$$
p(\boldsymbol{x}) = \frac{1}{\sqrt{(2\pi)^{n}|\Sigma|}} \exp \bigg( -\frac{1}{2}\sum_{i,j=1}^{n} (x_{i}-\mu _{i}) \Sigma _{i,j}^{-1} (x_{j}-\mu _{j}) \bigg)
\tag{1.52}
$$
我们定下下面的均值：
$$
E[x_{i}^{(1)} x_{i}^{(2)} \cdot \cdot \cdot x_{i}^{(m)}] = \int _{-\infty}^{\infty} x_{i}^{(1)} x_{i}^{(2)} \cdot \cdot \cdot x_{i}^{(m)} p(\boldsymbol{x}) d^{n} \boldsymbol{x} \\
= \frac{1}{\sqrt{(2\pi)^{n}|\Sigma|}} \int _{-\infty}^{\infty} x_{i}^{(1)} x_{i}^{(2)} \cdot \cdot \cdot x_{i}^{(m)} \exp (-\frac{1}{2}\sum_{i,j=1}^{n} x_{i}\Sigma _{i,j}^{-1}x_{j}) d^{n} \boldsymbol{x} \\
= \frac{I_{\Sigma , (x_{i}^{(1)}, x_{i}^{(2)} ,..., x_{i}^{(m)})}}{I_{\Sigma}}
\tag{1.53}
$$
其中$I_{\Sigma , (x_{i}^{(1)}, x_{i}^{(2)} ,..., x_{i}^{(m)})}$定义为：
$$
I_{\Sigma , (x_{i}^{(1)}, x_{i}^{(2)} ,..., x_{i}^{(m)})} = \int _{-\infty}^{\infty} x_{i}^{(1)} x_{i}^{(2)} \cdot \cdot \cdot x_{i}^{(m)} \exp (-\frac{1}{2}\sum_{i,j=1}^{n} x_{i}\Sigma _{i,j}^{-1}x_{j}) d^{n} \boldsymbol{x}
\tag{1.54}
$$
我们定义与$I_{\Sigma , (x_{i}^{(1)}, x_{i}^{(2)} ,..., x_{i}^{(m)})}$上对应的生成函数：
$$
X_{\Sigma , \boldsymbol{J}} = \int _{-\infty}^{\infty} \exp (-\frac{1}{2}\sum_{i,j=1}^{n} x_{i}\Sigma _{i,j}^{-1}x_{j} + \sum_{i=1}^{n}J_{i}x_{i}) d^{n} \boldsymbol{x}
\tag{1.55}
$$
我们对上面的生成函数连续求$m$次微分，就可以得到式$(1.54)$：
$$
\bigg( \frac{d}{d J_{i}^{(1)}} \frac{d}{d J_{i}^{(1)}} ... \frac{d}{d J_{i}^{(m)}} X_{\Sigma ,\boldsymbol{J}} \bigg) \bigg | _{\boldsymbol{J}=0} \\
= \int _{-\infty}^{\infty} x_{i}^{(1)} x_{i}^{(2)} \cdot \cdot \cdot x_{i}^{(m)} \exp (-\frac{1}{2}\sum_{i,j=1}^{n} x_{i}\Sigma _{i,j}^{-1}x_{j}) d^{n} \boldsymbol{x} \\
= I_{\Sigma , (x_{i}^{(1)}, x_{i}^{(2)} ,..., x_{i}^{(m)})}
\tag{1.56}
$$
与一维的情况相同，我们也先来研究式$(1.55)$的生成函数的指数部分：
$$
-\frac{1}{2}\sum_{i,j=1}^{n} x_{i}\Sigma _{i,j}^{-1}x_{j} + \sum_{i=1}^{n}J_{i}x_{i} \\
= ... \bigstar ^{1} \\
= - \frac{1}{2} \sum_{i,j=1}^{n} \omega _{i} \Sigma _{i,j}^{-1} \omega _{j} + \frac{1}{2} \sum_{i,j=1}^{n} J_{i} \Sigma _{i,j}^{-1} J_{j}
\tag{1.57}
$$
注：
1. 在电子书P27页式1.40，我没有看懂推导过程，因此空在这里；

将式$(1.57)$代入式$(1.55)$可得：
$$
X_{\Sigma , J} = \exp \Big( \frac{1}{2} \sum_{i,j=1}^{n} J_{i} \Sigma _{i,j}^{-1} J_{j} \Big) \int _{-\infty}^{\infty} \exp (-\frac{1}{2}\sum_{i,j=1}^{n} \omega _{i}\Sigma _{i,j}^{-1}\omega _{j} ) d^{n} \boldsymbol{\omega} \\
= \sqrt{(2\pi)^{n}|\Sigma |}\exp \Big( \frac{1}{2} \sum_{i,j=1}^{n} J_{i} \Sigma _{i,j}^{-1} J_{j} \Big)
$$


要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
要
